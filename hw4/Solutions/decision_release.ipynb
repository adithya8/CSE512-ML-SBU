{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import scipy.stats as ss\n",
    "\n",
    "import sklearn.model_selection as ms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\ndata = []\\nf = open('covtype.data','r')\\nwhile(1):\\n    line = f.readline()\\n    if  len(line) < 100:\\n        print line\\n    \\n    if len(line) == 0: break\\n    data.append(np.array([float(k) for k in line.split(',')]))\\n    if len(data) % 100000 == 0:\\n        print len(data)\\n        \\nf.close\\ndata = np.vstack(data)\\nN = data.shape[0]\\nidx = np.random.permutation(N)\\n\\n\\nX_test = data[:N/5,:]\\nX_train = data[N/5:,:]\\ny_test = X_test[:,-1]\\ny_train = X_train[:,-1]\\nX_test = X_test[:,:-1]\\nX_train = X_train[:,:-1]\\n\\n\\nsio.savemat('covtype.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\\n\\ndata = sio.loadmat('covtype.mat')\\nX_train = data['X_train']\\nX_test = data['X_test']\\ny_train = data['y_train'][0]\\ny_test = data['y_test'][0]\\n\\ny_idx_train = [np.where(np.equal(y_train,k))[0] for k in np.unique(y_train)]\\n\\nfor i in xrange(len(y_idx_train)):\\n    y_idx = y_idx_train[i]\\n    y_idx_train[i] = y_idx[np.random.choice(len(y_idx),len(y_idx)/1000+1,replace=False)]\\n    \\ny_idx_train = np.hstack(y_idx_train)\\ny_idx_train = np.random.permutation(y_idx_train)\\n\\nX_train = X_train[y_idx_train,:]\\ny_train = y_train[y_idx_train]\\n\\nsio.savemat('covtype_reduced.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\\n\\n\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# load your data (don't touch, just run)\n",
    "\"\"\"\n",
    "data = []\n",
    "f = open('covtype.data','r')\n",
    "while(1):\n",
    "    line = f.readline()\n",
    "    if  len(line) < 100:\n",
    "        print line\n",
    "    \n",
    "    if len(line) == 0: break\n",
    "    data.append(np.array([float(k) for k in line.split(',')]))\n",
    "    if len(data) % 100000 == 0:\n",
    "        print len(data)\n",
    "        \n",
    "f.close\n",
    "data = np.vstack(data)\n",
    "N = data.shape[0]\n",
    "idx = np.random.permutation(N)\n",
    "\n",
    "\n",
    "X_test = data[:N/5,:]\n",
    "X_train = data[N/5:,:]\n",
    "y_test = X_test[:,-1]\n",
    "y_train = X_train[:,-1]\n",
    "X_test = X_test[:,:-1]\n",
    "X_train = X_train[:,:-1]\n",
    "\n",
    "\n",
    "sio.savemat('covtype.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\n",
    "\n",
    "data = sio.loadmat('covtype.mat')\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train'][0]\n",
    "y_test = data['y_test'][0]\n",
    "\n",
    "y_idx_train = [np.where(np.equal(y_train,k))[0] for k in np.unique(y_train)]\n",
    "\n",
    "for i in xrange(len(y_idx_train)):\n",
    "    y_idx = y_idx_train[i]\n",
    "    y_idx_train[i] = y_idx[np.random.choice(len(y_idx),len(y_idx)/1000+1,replace=False)]\n",
    "    \n",
    "y_idx_train = np.hstack(y_idx_train)\n",
    "y_idx_train = np.random.permutation(y_idx_train)\n",
    "\n",
    "X_train = X_train[y_idx_train,:]\n",
    "y_train = y_train[y_idx_train]\n",
    "\n",
    "sio.savemat('covtype_reduced.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7.] [1. 2. 3. 4. 5. 6. 7.]\n(468, 54) (116202, 54) (468,) (116202,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = sio.loadmat('../covertype_release/covtype_reduced.mat')\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train'][0]\n",
    "y_test = data['y_test'][0]\n",
    "\n",
    "print (np.unique(y_train), np.unique(y_test))\n",
    "\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "entropy =  3.314182323161083\nconditional entropy =  3.3029598816135173\n"
     ]
    }
   ],
   "source": [
    "def entropy(label):\n",
    "    entropy = 0\n",
    "    for i in np.unique(label):\n",
    "        count_i = len(label[label == i])\n",
    "        count = len(label)\n",
    "        entropy += -(count_i/count)*np.log2((count_i/count)) if count_i != count else 0\n",
    "    return entropy\n",
    "\n",
    "def cond_entropy(label,split):\n",
    "    cond_entropy = 0\n",
    "    for i in np.unique(label):\n",
    "        for j in np.unique(split):\n",
    "            count_i_j = len(label[(label == i) & (split == j)])\n",
    "            count_j = len(split[split == j])\n",
    "            count = len(split)\n",
    "            cond_entropy += -(count_i_j/count)*np.log2(count_i_j/count_j) if count_i_j != 0 else 0\n",
    "\n",
    "    return cond_entropy\n",
    "\n",
    "random_sequences = sio.loadmat('../covertype_release/random_sequences.mat')\n",
    "\n",
    "s1 = random_sequences['s1'][0]\n",
    "s2 = random_sequences['s2'][0]\n",
    "\n",
    "print ('entropy = ', entropy(s1))\n",
    "print ('conditional entropy = ', cond_entropy(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "information gained in first step 0.34265604135138417\n"
     ]
    }
   ],
   "source": [
    "def find_best_split(x,y):\n",
    "    best_feat = 0\n",
    "    splitval = 0 #sorted(np.unique(X_train[:, best_feat]))[1] #0\n",
    "    max_info_gain = -np.inf\n",
    "    entropy_val = entropy(y)\n",
    "    for feat in range(x.shape[1]):        \n",
    "        for temp_splitval in sorted(np.unique(x[:, feat])):\n",
    "            y_split = y*0\n",
    "            y_split[x[:, feat] < temp_splitval] = 1\n",
    "            y_split[x[:, feat] >= temp_splitval] = 0\n",
    "            if entropy_val - cond_entropy(y, y_split) > max_info_gain:\n",
    "                best_feat = feat\n",
    "                splitval = temp_splitval\n",
    "                max_info_gain = entropy_val - cond_entropy(y, y_split)\n",
    "\n",
    "    set1 = np.argwhere(x[:, best_feat] < splitval).reshape(-1, )\n",
    "    set2 = np.argwhere(x[:, best_feat] >= splitval).reshape(-1, )\n",
    "\n",
    "    return best_feat, splitval, set1, set2\n",
    "\n",
    "best_feat, splitval, set1, set2 = find_best_split(X_train, y_train)\n",
    "y_new = y_train * 0\n",
    "y_new[set1] = 1\n",
    "print ('information gained in first step', entropy(y_train) - cond_entropy(y_train,y_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity(y):\n",
    "    return ss.mode(y)[1]/len(y+0.)\n",
    "    \n",
    "class Node:\n",
    "    def __init__(self,  sample_idx, nodeid,  is_leaf = True):\n",
    "        self.is_leaf = is_leaf\n",
    "        self.id = nodeid\n",
    "        self.sample_idx = sample_idx\n",
    "        self.children = []\n",
    "        \n",
    "    def visit_node(self, x):\n",
    "        if self.is_leaf:\n",
    "            return self.label\n",
    "        elif x[self.splitfeat] < self.splitval:\n",
    "            return self.children[0].visit_node(x)\n",
    "        return self.children[1].visit_node(x)\n",
    "        \n",
    "    def add_split_details(self, splitfeat, splitval)  :\n",
    "        self.splitfeat = splitfeat\n",
    "        self.splitval = splitval\n",
    "    \n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self, x,y):\n",
    "        m = len(y)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.maxid = -1\n",
    "        self.root = self.construct_node(np.array(range(m)))\n",
    "        self.leaves = [self.root]\n",
    "        \n",
    "    def print_tree(self):\n",
    "        print ('printing tree...')\n",
    "        def print_node(parent, node):\n",
    "            print (node.id, )\n",
    "            \n",
    "            if parent is not None:\n",
    "                print (', parent ', parent.id,)\n",
    "            else:\n",
    "                print (', ROOT', )\n",
    "                \n",
    "            print (', label ', node.label, )\n",
    "            if node.is_leaf: \n",
    "                print (', LEAF, ', 'nsamples %d, purity %.2f' %(len(node.sample_idx), purity(self.y[node.sample_idx])))\n",
    "                #node_ys = self.y[node.sample_idx]\n",
    "                #vals, counts = np.unique(node_ys, return_counts=True)\n",
    "                #if len(vals[counts == np.max(counts)]) > 1:\n",
    "                #    print (f\"CONFLICT HERE in {len(vals[counts == np.max(counts)])}\")\n",
    "            else:\n",
    "                print (', NONLEAF, split %d, val %.2f' % (node.splitfeat, node.splitval))\n",
    "            if not node.is_leaf:\n",
    "                for ch in node.children:\n",
    "                    print_node(node, ch)\n",
    "        print_node(None, self.root)\n",
    "        \n",
    "        \n",
    "    def construct_node(self, sample_idx):\n",
    "        node = Node(sample_idx, self.maxid + 1,  True)\n",
    "        node_ys = self.y[node.sample_idx]\n",
    "        vals, counts = np.unique(node_ys, return_counts=True)\n",
    "        if len(vals[counts == np.max(counts)]) == 1:\n",
    "            node.label = vals[counts == np.max(counts)][0] #ss.mode(self.y[sample_idx])[0].item() #0 # fill me in \n",
    "        else:\n",
    "            conflict_y_counts = [(i, len(self.y[self.y==i])) for i in vals[counts == np.max(counts)] ]\n",
    "            conflict_y_counts = sorted(conflict_y_counts, key=lambda a: a[1])\n",
    "            node.label = conflict_y_counts[-1][0]\n",
    "        node.entropy = entropy(self.y[sample_idx])\n",
    "        node.num_mistakes = np.sum(np.not_equal(node.label, self.y[sample_idx]))\n",
    "        self.maxid += 1\n",
    "        return node\n",
    "        \n",
    "    def report_train_err(self):\n",
    "        total_mistakes = 0\n",
    "        for leaf in self.leaves:\n",
    "            total_mistakes += leaf.num_mistakes\n",
    "        return total_mistakes / (len(self.y)+0.)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        return self.root.visit_node(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "printing tree...\n",
      "0\n",
      ", ROOT\n",
      ", label  2.0\n",
      ", LEAF,  nsamples 468, purity 0.44\n",
      "current train err: 0.5641025641025641\n",
      "current test err: 0.3138069912738163\n",
      "printing tree...\n",
      "0\n",
      ", ROOT\n",
      ", label  2.0\n",
      ", NONLEAF, split 0, val 2844.00\n",
      "1\n",
      ", parent  0\n",
      ", label  2.0\n",
      ", LEAF,  nsamples 116, purity 0.46\n",
      "2\n",
      ", parent  0\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 352, purity 0.51\n",
      "one step train err: 0.5021367521367521\n",
      "one step test err: 0.4959983477048588\n",
      "test error after 1 steps: 0.496, train error: 0.502\n",
      "test error after 2 steps: 0.776, train error: 0.491\n",
      "test error after 3 steps: 0.818, train error: 0.549\n",
      "test error after 4 steps: 0.826, train error: 0.551\n",
      "test error after 5 steps: 0.546, train error: 0.543\n",
      "test error after 6 steps: 0.365, train error: 0.524\n",
      "test error after 7 steps: 0.322, train error: 0.526\n",
      "test error after 8 steps: 0.324, train error: 0.524\n",
      "test error after 9 steps: 0.316, train error: 0.524\n",
      "test error after 10 steps: 0.596, train error: 0.517\n",
      "test error after 11 steps: 0.596, train error: 0.513\n",
      "test error after 12 steps: 0.596, train error: 0.504\n",
      "test error after 13 steps: 0.661, train error: 0.491\n",
      "test error after 14 steps: 0.661, train error: 0.481\n",
      "test error after 15 steps: 0.661, train error: 0.468\n",
      "test error after 16 steps: 0.659, train error: 0.468\n",
      "test error after 17 steps: 0.659, train error: 0.468\n",
      "test error after 18 steps: 0.659, train error: 0.466\n",
      "test error after 19 steps: 0.659, train error: 0.468\n",
      "test error after 20 steps: 0.659, train error: 0.47\n",
      "test error after 21 steps: 0.659, train error: 0.474\n",
      "test error after 22 steps: 0.659, train error: 0.47\n",
      "test error after 23 steps: 0.659, train error: 0.479\n",
      "test error after 24 steps: 0.659, train error: 0.481\n",
      "test error after 25 steps: 0.659, train error: 0.483\n",
      "25 step train err: 0.4829059829059829\n",
      "25 step test err: 0.7757009345794392\n"
     ]
    }
   ],
   "source": [
    "def get_test_err(tree):\n",
    "    # get test error\n",
    "    num_test_mistakes = 0\n",
    "    for k in range(len(y_test)):\n",
    "        x,y = X_test[k,:],y_test[k]\n",
    "        if y != tree.predict(x):\n",
    "            num_test_mistakes += 1\n",
    "    return num_test_mistakes / (len(y_test)+0.)\n",
    "\n",
    "tree = Tree(X_train,y_train)\n",
    "tree.print_tree()\n",
    "print ('current train err:', tree.report_train_err())\n",
    "print ('current test err:', get_test_err(tree))\n",
    "\n",
    "\n",
    "# my first split\n",
    "best_feat, splitval, set1, set2 = find_best_split(X_train, y_train)\n",
    " \n",
    "left_child = tree.construct_node(set1)\n",
    "right_child = tree.construct_node(set2)\n",
    "tree.root.is_leaf = False\n",
    "tree.leaves.pop(tree.leaves.index(tree.root))\n",
    "tree.root.add_split_details(splitfeat = best_feat, splitval = splitval)\n",
    "\n",
    "\n",
    "tree.root.children = [left_child, right_child]\n",
    "tree.leaves.extend(tree.root.children)\n",
    "\n",
    "tree.print_tree()\n",
    "print ('one step train err:', tree.report_train_err())\n",
    "print ('one step test err:', get_test_err(tree))\n",
    "\n",
    "while (tree.maxid <=51):\n",
    "    curr_node = tree.leaves[0] #tree.leaves.pop(0)\n",
    "    if purity(tree.y[curr_node.sample_idx]).item() == 1: #overfitting param\n",
    "        print (f\"Node {curr_node.id} is pure\")\n",
    "        tree.leaves.pop(tree.leaves.index(curr_node))\n",
    "        continue\n",
    "    #print (f\"Node {curr_node.id} purity = {np.around(purity(tree.y[curr_node.sample_idx]), 3)}, \")\n",
    "    print(f\"test error after {tree.maxid//2} steps: {np.around(get_test_err(tree), 3)}, train error: {np.around(tree.report_train_err(), 3)}\")\n",
    "\n",
    "    best_feat, splitval, set1, set2 = find_best_split(tree.x[curr_node.sample_idx], tree.y[curr_node.sample_idx])\n",
    "    left_child = tree.construct_node(np.array(set1))\n",
    "    right_child = tree.construct_node(np.array(set2))\n",
    "    tree.leaves[0].is_leaf = False\n",
    "    tree.leaves[0].add_split_details(splitfeat = best_feat, splitval = splitval)\n",
    "    tree.leaves[0].children = [left_child, right_child]\n",
    "    tree.leaves.extend(tree.leaves[0].children)\n",
    "    tree.leaves.pop(0)\n",
    "\n",
    "print ('25 step train err:', tree.report_train_err())\n",
    "print ('25 step test err:', get_test_err(tree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "printing tree...\n0\n, ROOT\n, label  2.0\n, NONLEAF, split 0, val 2844.00\n1\n, parent  0\n, label  2.0\n, NONLEAF, split 0, val 2525.00\n3\n, parent  1\n, label  2.0\n, NONLEAF, split 9, val 757.00\n7\n, parent  3\n, label  2.0\n, NONLEAF, split 1, val 299.00\n15\n, parent  7\n, label  1.0\n, NONLEAF, split 0, val 2739.00\n31\n, parent  15\n, label  2.0\n, LEAF,  nsamples 3, purity 0.33\n32\n, parent  15\n, label  1.0\n, LEAF,  nsamples 3, purity 0.33\n16\n, parent  7\n, label  1.0\n, NONLEAF, split 0, val 3172.00\n33\n, parent  16\n, label  5.0\n, LEAF,  nsamples 1, purity 1.00\n34\n, parent  16\n, label  1.0\n, LEAF,  nsamples 2, purity 0.50\n8\n, parent  3\n, label  1.0\n, NONLEAF, split 0, val 2965.00\n17\n, parent  8\n, label  2.0\n, NONLEAF, split 2, val 23.00\n35\n, parent  17\n, label  2.0\n, LEAF,  nsamples 4, purity 0.25\n36\n, parent  17\n, label  1.0\n, LEAF,  nsamples 4, purity 0.50\n18\n, parent  8\n, label  1.0\n, NONLEAF, split 0, val 3172.00\n37\n, parent  18\n, label  1.0\n, LEAF,  nsamples 10, purity 0.70\n38\n, parent  18\n, label  1.0\n, LEAF,  nsamples 10, purity 0.50\n4\n, parent  1\n, label  1.0\n, NONLEAF, split 0, val 2942.00\n9\n, parent  4\n, label  2.0\n, NONLEAF, split 3, val 331.00\n19\n, parent  9\n, label  1.0\n, NONLEAF, split 0, val 3172.00\n39\n, parent  19\n, label  1.0\n, LEAF,  nsamples 5, purity 0.40\n40\n, parent  19\n, label  1.0\n, LEAF,  nsamples 5, purity 0.60\n20\n, parent  9\n, label  1.0\n, NONLEAF, split 0, val 3112.00\n41\n, parent  20\n, label  1.0\n, LEAF,  nsamples 4, purity 0.50\n42\n, parent  20\n, label  1.0\n, LEAF,  nsamples 7, purity 0.43\n10\n, parent  4\n, label  1.0\n, NONLEAF, split 0, val 2965.00\n21\n, parent  10\n, label  2.0\n, NONLEAF, split 3, val 210.00\n43\n, parent  21\n, label  1.0\n, LEAF,  nsamples 5, purity 0.60\n44\n, parent  21\n, label  1.0\n, LEAF,  nsamples 10, purity 0.60\n22\n, parent  10\n, label  1.0\n, NONLEAF, split 0, val 2965.00\n45\n, parent  22\n, label  1.0\n, LEAF,  nsamples 11, purity 0.45\n46\n, parent  22\n, label  1.0\n, LEAF,  nsamples 32, purity 0.59\n2\n, parent  0\n, label  1.0\n, NONLEAF, split 0, val 3171.00\n5\n, parent  2\n, label  1.0\n, NONLEAF, split 0, val 2886.00\n11\n, parent  5\n, label  1.0\n, NONLEAF, split 0, val 2783.00\n23\n, parent  11\n, label  1.0\n, NONLEAF, split 0, val 2966.00\n47\n, parent  23\n, label  3.0\n, LEAF,  nsamples 2, purity 0.50\n48\n, parent  23\n, label  1.0\n, LEAF,  nsamples 4, purity 0.50\n24\n, parent  11\n, label  1.0\n, NONLEAF, split 0, val 2694.00\n49\n, parent  24\n, label  1.0\n, LEAF,  nsamples 8, purity 0.62\n50\n, parent  24\n, label  1.0\n, LEAF,  nsamples 39, purity 0.54\n12\n, parent  5\n, label  2.0\n, NONLEAF, split 0, val 2965.00\n25\n, parent  12\n, label  2.0\n, NONLEAF, split 0, val 2754.00\n51\n, parent  25\n, label  1.0\n, LEAF,  nsamples 13, purity 0.54\n52\n, parent  25\n, label  1.0\n, LEAF,  nsamples 53, purity 0.53\n26\n, parent  12\n, label  1.0\n, LEAF,  nsamples 101, purity 0.47\n6\n, parent  2\n, label  2.0\n, NONLEAF, split 0, val 3054.00\n13\n, parent  6\n, label  2.0\n, NONLEAF, split 0, val 2942.00\n27\n, parent  13\n, label  1.0\n, LEAF,  nsamples 17, purity 0.47\n28\n, parent  13\n, label  1.0\n, LEAF,  nsamples 46, purity 0.54\n14\n, parent  6\n, label  1.0\n, NONLEAF, split 0, val 2694.00\n29\n, parent  14\n, label  1.0\n, LEAF,  nsamples 11, purity 0.55\n30\n, parent  14\n, label  1.0\n, LEAF,  nsamples 58, purity 0.52\n"
     ]
    }
   ],
   "source": [
    "tree.print_tree()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.6.10 64-bit",
   "display_name": "Python 3.6.10 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "04c40bc1924228ecae069f0a0752ec329fab5eb29451cd4e89c215b5a2e0afc3"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}