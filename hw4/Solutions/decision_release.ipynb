{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import scipy.stats as ss\n",
    "\n",
    "import sklearn.model_selection as ms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\ndata = []\\nf = open('covtype.data','r')\\nwhile(1):\\n    line = f.readline()\\n    if  len(line) < 100:\\n        print line\\n    \\n    if len(line) == 0: break\\n    data.append(np.array([float(k) for k in line.split(',')]))\\n    if len(data) % 100000 == 0:\\n        print len(data)\\n        \\nf.close\\ndata = np.vstack(data)\\nN = data.shape[0]\\nidx = np.random.permutation(N)\\n\\n\\nX_test = data[:N/5,:]\\nX_train = data[N/5:,:]\\ny_test = X_test[:,-1]\\ny_train = X_train[:,-1]\\nX_test = X_test[:,:-1]\\nX_train = X_train[:,:-1]\\n\\n\\nsio.savemat('covtype.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\\n\\ndata = sio.loadmat('covtype.mat')\\nX_train = data['X_train']\\nX_test = data['X_test']\\ny_train = data['y_train'][0]\\ny_test = data['y_test'][0]\\n\\ny_idx_train = [np.where(np.equal(y_train,k))[0] for k in np.unique(y_train)]\\n\\nfor i in xrange(len(y_idx_train)):\\n    y_idx = y_idx_train[i]\\n    y_idx_train[i] = y_idx[np.random.choice(len(y_idx),len(y_idx)/1000+1,replace=False)]\\n    \\ny_idx_train = np.hstack(y_idx_train)\\ny_idx_train = np.random.permutation(y_idx_train)\\n\\nX_train = X_train[y_idx_train,:]\\ny_train = y_train[y_idx_train]\\n\\nsio.savemat('covtype_reduced.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\\n\\n\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# load your data (don't touch, just run)\n",
    "\"\"\"\n",
    "data = []\n",
    "f = open('covtype.data','r')\n",
    "while(1):\n",
    "    line = f.readline()\n",
    "    if  len(line) < 100:\n",
    "        print line\n",
    "    \n",
    "    if len(line) == 0: break\n",
    "    data.append(np.array([float(k) for k in line.split(',')]))\n",
    "    if len(data) % 100000 == 0:\n",
    "        print len(data)\n",
    "        \n",
    "f.close\n",
    "data = np.vstack(data)\n",
    "N = data.shape[0]\n",
    "idx = np.random.permutation(N)\n",
    "\n",
    "\n",
    "X_test = data[:N/5,:]\n",
    "X_train = data[N/5:,:]\n",
    "y_test = X_test[:,-1]\n",
    "y_train = X_train[:,-1]\n",
    "X_test = X_test[:,:-1]\n",
    "X_train = X_train[:,:-1]\n",
    "\n",
    "\n",
    "sio.savemat('covtype.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\n",
    "\n",
    "data = sio.loadmat('covtype.mat')\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train'][0]\n",
    "y_test = data['y_test'][0]\n",
    "\n",
    "y_idx_train = [np.where(np.equal(y_train,k))[0] for k in np.unique(y_train)]\n",
    "\n",
    "for i in xrange(len(y_idx_train)):\n",
    "    y_idx = y_idx_train[i]\n",
    "    y_idx_train[i] = y_idx[np.random.choice(len(y_idx),len(y_idx)/1000+1,replace=False)]\n",
    "    \n",
    "y_idx_train = np.hstack(y_idx_train)\n",
    "y_idx_train = np.random.permutation(y_idx_train)\n",
    "\n",
    "X_train = X_train[y_idx_train,:]\n",
    "y_train = y_train[y_idx_train]\n",
    "\n",
    "sio.savemat('covtype_reduced.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7.] [1. 2. 3. 4. 5. 6. 7.]\n(468, 54) (116202, 54) (468,) (116202,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = sio.loadmat('../covertype_release/covtype_reduced.mat')\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train'][0]\n",
    "y_test = data['y_test'][0]\n",
    "\n",
    "print (np.unique(y_train), np.unique(y_test))\n",
    "\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "entropy =  3.314182323161083\nconditional entropy =  3.302959881613517\n"
     ]
    }
   ],
   "source": [
    "def entropy(label):\n",
    "    entropy = 0\n",
    "    for i in np.unique(label):\n",
    "        count_i = len(label[label == i])\n",
    "        count = len(label)\n",
    "        entropy += -(count_i/count)*np.log2((count_i/count)) if (count_i != count or count_i != 0) else 0\n",
    "    return entropy\n",
    "\n",
    "def cond_entropy(label,split):\n",
    "    cond_entropy = 0\n",
    "    for j in np.unique(split):\n",
    "            cond_entropy += entropy(label[split == j])*len(split[split==j])/len(split)\n",
    "    return cond_entropy\n",
    "\n",
    "random_sequences = sio.loadmat('../covertype_release/random_sequences.mat')\n",
    "\n",
    "s1 = random_sequences['s1'][0]\n",
    "s2 = random_sequences['s2'][0]\n",
    "\n",
    "print ('entropy = ', entropy(s1))\n",
    "print ('conditional entropy = ', cond_entropy(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "information gained in first step 0.3426560413513844\n"
     ]
    }
   ],
   "source": [
    "def find_best_split(x,y):\n",
    "    best_feat = 0\n",
    "    splitval = 0 #sorted(np.unique(X_train[:, best_feat]))[1] #0\n",
    "    max_info_gain = -np.inf\n",
    "    entropy_val = entropy(y)\n",
    "    for feat in range(x.shape[1]):\n",
    "        discrete_feats = sorted(np.unique(x[:, feat]))[1:]\n",
    "        #discrete_feats = discrete_feats[::int(len(discrete_feats)//3)] if len(discrete_feats) > 2 else discrete_feats\n",
    "        for temp_splitval in discrete_feats:\n",
    "            y_split = y*0\n",
    "            y_split[x[:, feat] < temp_splitval] = 1\n",
    "            #y_split[x[:, feat] >= temp_splitval] = 0\n",
    "            if entropy_val - cond_entropy(y, y_split) > max_info_gain:\n",
    "                best_feat = feat\n",
    "                splitval = temp_splitval\n",
    "                max_info_gain = entropy_val - cond_entropy(y, y_split)\n",
    "\n",
    "    set1 = np.argwhere(x[:, best_feat] < splitval).reshape(-1, )\n",
    "    set2 = np.argwhere(x[:, best_feat] >= splitval).reshape(-1, )\n",
    "\n",
    "    return best_feat, splitval, set1, set2\n",
    "\n",
    "best_feat, splitval, set1, set2 = find_best_split(X_train, y_train)\n",
    "y_new = y_train * 0\n",
    "y_new[set1] = 1\n",
    "print ('information gained in first step', entropy(y_train) - cond_entropy(y_train,y_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity(y):\n",
    "    return ss.mode(y)[1]/len(y+0.)\n",
    "    #return ss.mode(y)[1]/len(y)\n",
    "    \n",
    "class Node:\n",
    "    def __init__(self,  sample_idx, nodeid,  is_leaf = True):\n",
    "        self.is_leaf = is_leaf\n",
    "        self.id = nodeid\n",
    "        self.sample_idx = sample_idx\n",
    "        self.children = []\n",
    "        \n",
    "    def visit_node(self, x):\n",
    "        if self.is_leaf:\n",
    "            return self.label\n",
    "        elif x[self.splitfeat] >= self.splitval:\n",
    "            return self.children[0].visit_node(x)\n",
    "        return self.children[1].visit_node(x)\n",
    "        \n",
    "    def add_split_details(self, splitfeat, splitval)  :\n",
    "        self.splitfeat = splitfeat\n",
    "        self.splitval = splitval\n",
    "    \n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self, x,y):\n",
    "        m = len(y)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.maxid = -1\n",
    "        self.root = self.construct_node(np.array(range(m)))\n",
    "        self.leaves = [self.root]\n",
    "        \n",
    "    def print_tree(self):\n",
    "        print ('printing tree...')\n",
    "        def print_node(parent, node):\n",
    "            print (node.id, )\n",
    "            \n",
    "            if parent is not None:\n",
    "                print (', parent ', parent.id,)\n",
    "            else:\n",
    "                print (', ROOT', )\n",
    "                \n",
    "            print (', label ', node.label, )\n",
    "            if node.is_leaf: \n",
    "                print (', LEAF, ', 'nsamples %d, purity %.2f' %(len(node.sample_idx), purity(self.y[node.sample_idx])))\n",
    "                #node_ys = self.y[node.sample_idx]\n",
    "                #vals, counts = np.unique(node_ys, return_counts=True)\n",
    "                #if len(vals[counts == np.max(counts)]) > 1:\n",
    "                #    print (f\"CONFLICT HERE in {len(vals[counts == np.max(counts)])}\")\n",
    "            else:\n",
    "                print (f\"NONLEAF, split {node.splitfeat}, val {node.splitval}, nsamples {len(node.sample_idx)}\")\n",
    "            if not node.is_leaf:\n",
    "                for ch in node.children:\n",
    "                    print_node(node, ch)\n",
    "        print_node(None, self.root)\n",
    "        \n",
    "    def construct_node(self, sample_idx):\n",
    "        node = Node(sample_idx, self.maxid + 1,  True)\n",
    "        node_ys = self.y[node.sample_idx]\n",
    "        vals, counts = np.unique(node_ys, return_counts=True)\n",
    "        if len(vals[counts == np.max(counts)]) == 1:\n",
    "            node.label = vals[counts == np.max(counts)][0] #ss.mode(self.y[sample_idx])[0].item() #0 # fill me in \n",
    "        else:\n",
    "            conflict_y_counts = [(i, len(self.y[self.y==i])) for i in vals[counts == np.max(counts)] ]\n",
    "            conflict_y_counts = sorted(conflict_y_counts, key=lambda a: a[1])\n",
    "            node.label = conflict_y_counts[-1][0]\n",
    "        #node.label = ss.mode(self.y[sample_idx])[0].item()\n",
    "        node.entropy = entropy(self.y[sample_idx])\n",
    "        node.num_mistakes = np.sum(np.not_equal(node.label, self.y[sample_idx]))\n",
    "        self.maxid += 1\n",
    "        return node\n",
    "        \n",
    "    def report_train_err(self):\n",
    "        total_mistakes = 0\n",
    "        for leaf in self.leaves:\n",
    "            total_mistakes += leaf.num_mistakes\n",
    "        return total_mistakes / (len(self.y)+0.)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        return self.root.visit_node(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "printing tree...\n",
      "0\n",
      ", ROOT\n",
      ", label  2.0\n",
      ", LEAF,  nsamples 468, purity 0.44\n",
      "current train err: 0.5641025641025641\n",
      "current test err: 0.3138069912738163\n",
      "printing tree...\n",
      "0\n",
      ", ROOT\n",
      ", label  2.0\n",
      "NONLEAF, split 0, val 2844.0, nsamples 468\n",
      "1\n",
      ", parent  0\n",
      ", label  2.0\n",
      ", LEAF,  nsamples 116, purity 0.46\n",
      "2\n",
      ", parent  0\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 352, purity 0.51\n",
      "one step train err: 0.5021367521367521\n",
      "one step test err: 0.6024336930517546\n"
     ]
    }
   ],
   "source": [
    "def get_test_err(tree):\n",
    "    # get test error\n",
    "    num_test_mistakes = 0\n",
    "    for k in range(len(y_test)):\n",
    "        x,y = X_test[k,:],y_test[k]\n",
    "        if y != tree.predict(x):\n",
    "            num_test_mistakes += 1\n",
    "    return num_test_mistakes / (len(y_test)+0.)\n",
    "\n",
    "def get_train_err(tree):\n",
    "    # get train error\n",
    "    num_test_mistakes = 0\n",
    "    for k in range(len(y_train)):\n",
    "        x,y = X_train[k,:],y_train[k]\n",
    "        if y != tree.predict(x):\n",
    "            num_test_mistakes += 1\n",
    "    return num_test_mistakes / (len(y_train)+0.)\n",
    "\n",
    "tree = Tree(X_train,y_train)\n",
    "tree.print_tree()\n",
    "print ('current train err:', tree.report_train_err())\n",
    "print ('current test err:', get_test_err(tree))\n",
    "\n",
    "\n",
    "# my first split\n",
    "best_feat, splitval, set1, set2 = find_best_split(X_train, y_train)\n",
    " \n",
    "left_child = tree.construct_node(set1)\n",
    "right_child = tree.construct_node(set2)\n",
    "tree.root.is_leaf = False\n",
    "tree.leaves.pop(tree.leaves.index(tree.root))\n",
    "tree.root.add_split_details(splitfeat = best_feat, splitval = splitval)\n",
    "\n",
    "\n",
    "tree.root.children = [left_child, right_child]\n",
    "tree.leaves.extend(tree.root.children)\n",
    "\n",
    "tree.print_tree()\n",
    "print ('one step train err:', tree.report_train_err())\n",
    "print ('one step test err:', get_test_err(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\\texttt { test error after 1 steps: 0.602, train error: 0.502 } \\\\\n",
      "\\texttt { test error after 2 steps: 0.602, train error: 0.491 } \\\\\n",
      "\\texttt { test error after 3 steps: 0.602, train error: 0.483 } \\\\\n",
      "\\texttt { test error after 4 steps: 0.602, train error: 0.476 } \\\\\n",
      "\\texttt { test error after 5 steps: 0.314, train error: 0.534 } \\\\\n",
      "\\texttt { test error after 6 steps: 0.314, train error: 0.515 } \\\\\n",
      "\\texttt { test error after 7 steps: 0.602, train error: 0.517 } \\\\\n",
      "\\texttt { test error after 8 steps: 0.602, train error: 0.504 } \\\\\n",
      "\\texttt { test error after 9 steps: 0.602, train error: 0.494 } \\\\\n",
      "\\texttt { test error after 10 steps: 0.602, train error: 0.481 } \\\\\n",
      "\\texttt { test error after 11 steps: 0.602, train error: 0.466 } \\\\\n",
      "\\texttt { test error after 12 steps: 0.602, train error: 0.459 } \\\\\n",
      "\\texttt { test error after 13 steps: 0.602, train error: 0.457 } \\\\\n",
      "\\texttt { test error after 14 steps: 0.602, train error: 0.449 } \\\\\n",
      "\\texttt { test error after 15 steps: 0.605, train error: 0.451 } \\\\\n",
      "\\texttt { test error after 16 steps: 0.785, train error: 0.449 } \\\\\n",
      "\\texttt { test error after 17 steps: 0.758, train error: 0.449 } \\\\\n",
      "\\texttt { test error after 18 steps: 0.794, train error: 0.447 } \\\\\n",
      "\\texttt { test error after 19 steps: 0.794, train error: 0.444 } \\\\\n",
      "\\texttt { test error after 20 steps: 0.806, train error: 0.442 } \\\\\n",
      "\\texttt { test error after 21 steps: 0.806, train error: 0.44 } \\\\\n",
      "\\texttt { test error after 22 steps: 0.806, train error: 0.434 } \\\\\n",
      "\\texttt { test error after 23 steps: 0.806, train error: 0.434 } \\\\\n",
      "\\texttt { test error after 24 steps: 0.806, train error: 0.434 } \\\\\n",
      "\\texttt { test error after 25 steps: 0.806, train error: 0.432 } \\\\\n",
      "25 step train err: 0.42948717948717946\n",
      "25 step test err: 0.8062683946920018\n"
     ]
    }
   ],
   "source": [
    "while (tree.maxid <=51):\n",
    "    \n",
    "    leaves = tree.leaves\n",
    "    #storing (leaf, purity)\n",
    "    leaves_purity = [ (leaf, purity(tree.y[leaf.sample_idx]).item(), len(leaf.sample_idx)) for leaf in leaves]\n",
    "    #Sorting leaves based on purity (increasing order) and number of samples (decreasing order)\n",
    "    leaves_purity = sorted(leaves_purity, key=lambda a: (a[1], -a[2]))\n",
    "    #storing the leaves in the ascending order of purity.\n",
    "    #tree.leaves = list(map(lambda a: a[0], leaves_purity))\n",
    "    \n",
    "    #Picking the leaf with the least purity\n",
    "    curr_node = list(map(lambda a: a[0], leaves_purity))[0]\n",
    "    \n",
    "    #curr_node = tree.leaves[0] #tree.leaves.pop(0)\n",
    "    #overfitting param/stopping condn.\n",
    "    if purity(tree.y[curr_node.sample_idx]).item() == 1 :#or len(curr_node.sample_idx)<=2: \n",
    "        print (f\"Node {curr_node.id} is pure\")\n",
    "        tree.leaves.pop(tree.leaves.index(curr_node))\n",
    "        continue\n",
    "    #print (f\"Node {curr_node.id} purity = {np.around(purity(tree.y[curr_node.sample_idx]), 3)}, \")\n",
    "    open_b, close_b = \"{\",\"}\"\n",
    "    print(f\"\\\\texttt {open_b} test error after {tree.maxid//2} steps: {np.around(get_test_err(tree), 3)}, train error: {np.around(tree.report_train_err(), 3)} {close_b} \\\\\\\\\")\n",
    "\n",
    "    best_feat, splitval, set1, set2 = find_best_split(X_train[curr_node.sample_idx], y_train[curr_node.sample_idx])\n",
    "    #print ((y_train[set1]), (y_train[set2]), (y_train[curr_node.sample_idx]))\n",
    "    #print (purity(y_train[set1]), purity(y_train[set2]), purity(y_train[curr_node.sample_idx]))\n",
    "    left_child = tree.construct_node(np.array(set1))\n",
    "    right_child = tree.construct_node(np.array(set2))\n",
    "    \n",
    "    #break\n",
    "    curr_node.is_leaf = False\n",
    "    curr_node.add_split_details(splitfeat = best_feat, splitval = splitval)\n",
    "    curr_node.children = [left_child, right_child]\n",
    "    tree.leaves.extend(curr_node.children)\n",
    "\n",
    "    tree.leaves.pop(tree.leaves.index(curr_node))\n",
    "    \n",
    "    \n",
    "\n",
    "print ('25 step train err:', tree.report_train_err())\n",
    "print ('25 step test err:', get_test_err(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "printing tree...\n0\n, ROOT\n, label  2.0\nNONLEAF, split 0, val 2844.0, nsamples 468\n1\n, parent  0\n, label  2.0\nNONLEAF, split 0, val 2525.0, nsamples 116\n3\n, parent  1\n, label  2.0\nNONLEAF, split 9, val 757.0, nsamples 37\n29\n, parent  3\n, label  1.0\nNONLEAF, split 1, val 299.0, nsamples 9\n31\n, parent  29\n, label  1.0\nNONLEAF, split 0, val 2739.0, nsamples 6\n33\n, parent  31\n, label  1.0\nNONLEAF, split 0, val 3131.0, nsamples 3\n35\n, parent  33\n, label  3.0\n, LEAF,  nsamples 1, purity 1.00\n36\n, parent  33\n, label  1.0\nNONLEAF, split 0, val 3172.0, nsamples 2\n39\n, parent  36\n, label  3.0\n, LEAF,  nsamples 1, purity 1.00\n40\n, parent  36\n, label  5.0\n, LEAF,  nsamples 1, purity 1.00\n34\n, parent  31\n, label  1.0\nNONLEAF, split 0, val 2739.0, nsamples 3\n37\n, parent  34\n, label  5.0\n, LEAF,  nsamples 1, purity 1.00\n38\n, parent  34\n, label  1.0\nNONLEAF, split 0, val 3172.0, nsamples 2\n41\n, parent  38\n, label  3.0\n, LEAF,  nsamples 1, purity 1.00\n42\n, parent  38\n, label  5.0\n, LEAF,  nsamples 1, purity 1.00\n32\n, parent  29\n, label  1.0\n, LEAF,  nsamples 3, purity 0.67\n30\n, parent  3\n, label  1.0\n, LEAF,  nsamples 28, purity 0.54\n4\n, parent  1\n, label  1.0\nNONLEAF, split 0, val 2942.0, nsamples 79\n5\n, parent  4\n, label  2.0\nNONLEAF, split 3, val 331.0, nsamples 21\n7\n, parent  5\n, label  1.0\n, LEAF,  nsamples 10, purity 0.60\n8\n, parent  5\n, label  1.0\n, LEAF,  nsamples 11, purity 0.64\n6\n, parent  4\n, label  1.0\n, LEAF,  nsamples 58, purity 0.57\n2\n, parent  0\n, label  1.0\nNONLEAF, split 0, val 3171.0, nsamples 352\n9\n, parent  2\n, label  1.0\nNONLEAF, split 0, val 2886.0, nsamples 220\n11\n, parent  9\n, label  1.0\nNONLEAF, split 0, val 2783.0, nsamples 53\n27\n, parent  11\n, label  1.0\n, LEAF,  nsamples 6, purity 0.67\n28\n, parent  11\n, label  1.0\n, LEAF,  nsamples 47, purity 0.57\n12\n, parent  9\n, label  2.0\nNONLEAF, split 0, val 2965.0, nsamples 167\n19\n, parent  12\n, label  2.0\n, LEAF,  nsamples 66, purity 0.53\n20\n, parent  12\n, label  1.0\nNONLEAF, split 0, val 2886.0, nsamples 101\n21\n, parent  20\n, label  2.0\n, LEAF,  nsamples 22, purity 0.59\n22\n, parent  20\n, label  1.0\n, LEAF,  nsamples 79, purity 0.52\n10\n, parent  2\n, label  2.0\nNONLEAF, split 0, val 3054.0, nsamples 132\n13\n, parent  10\n, label  2.0\nNONLEAF, split 0, val 2942.0, nsamples 63\n17\n, parent  13\n, label  1.0\nNONLEAF, split 9, val 895.0, nsamples 17\n23\n, parent  17\n, label  1.0\nNONLEAF, split 0, val 3200.0, nsamples 2\n25\n, parent  23\n, label  3.0\n, LEAF,  nsamples 1, purity 1.00\n26\n, parent  23\n, label  5.0\n, LEAF,  nsamples 1, purity 1.00\n24\n, parent  17\n, label  1.0\n, LEAF,  nsamples 15, purity 0.67\n18\n, parent  13\n, label  1.0\n, LEAF,  nsamples 46, purity 0.54\n14\n, parent  10\n, label  1.0\nNONLEAF, split 0, val 2694.0, nsamples 69\n15\n, parent  14\n, label  1.0\n, LEAF,  nsamples 11, purity 0.55\n16\n, parent  14\n, label  1.0\nNONLEAF, split 0, val 2694.0, nsamples 58\n43\n, parent  16\n, label  1.0\nNONLEAF, split 0, val 3143.0, nsamples 10\n45\n, parent  43\n, label  1.0\nNONLEAF, split 0, val 3131.0, nsamples 5\n47\n, parent  45\n, label  2.0\nNONLEAF, split 0, val 3131.0, nsamples 2\n51\n, parent  47\n, label  3.0\n, LEAF,  nsamples 1, purity 1.00\n52\n, parent  47\n, label  5.0\n, LEAF,  nsamples 1, purity 1.00\n48\n, parent  45\n, label  1.0\nNONLEAF, split 0, val 2739.0, nsamples 3\n49\n, parent  48\n, label  1.0\n, LEAF,  nsamples 1, purity 1.00\n50\n, parent  48\n, label  3.0\n, LEAF,  nsamples 2, purity 0.50\n46\n, parent  43\n, label  1.0\n, LEAF,  nsamples 5, purity 0.60\n44\n, parent  16\n, label  1.0\n, LEAF,  nsamples 48, purity 0.58\n"
     ]
    }
   ],
   "source": [
    "tree.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.6.10 64-bit ('py3': conda)",
   "display_name": "Python 3.6.10 64-bit ('py3': conda)",
   "metadata": {
    "interpreter": {
     "hash": "04c40bc1924228ecae069f0a0752ec329fab5eb29451cd4e89c215b5a2e0afc3"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}