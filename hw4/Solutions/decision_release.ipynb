{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import scipy.stats as ss\n",
    "\n",
    "import sklearn.model_selection as ms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata = []\\nf = open('covtype.data','r')\\nwhile(1):\\n    line = f.readline()\\n    if  len(line) < 100:\\n        print line\\n    \\n    if len(line) == 0: break\\n    data.append(np.array([float(k) for k in line.split(',')]))\\n    if len(data) % 100000 == 0:\\n        print len(data)\\n        \\nf.close\\ndata = np.vstack(data)\\nN = data.shape[0]\\nidx = np.random.permutation(N)\\n\\n\\nX_test = data[:N/5,:]\\nX_train = data[N/5:,:]\\ny_test = X_test[:,-1]\\ny_train = X_train[:,-1]\\nX_test = X_test[:,:-1]\\nX_train = X_train[:,:-1]\\n\\n\\nsio.savemat('covtype.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\\n\\ndata = sio.loadmat('covtype.mat')\\nX_train = data['X_train']\\nX_test = data['X_test']\\ny_train = data['y_train'][0]\\ny_test = data['y_test'][0]\\n\\ny_idx_train = [np.where(np.equal(y_train,k))[0] for k in np.unique(y_train)]\\n\\nfor i in xrange(len(y_idx_train)):\\n    y_idx = y_idx_train[i]\\n    y_idx_train[i] = y_idx[np.random.choice(len(y_idx),len(y_idx)/1000+1,replace=False)]\\n    \\ny_idx_train = np.hstack(y_idx_train)\\ny_idx_train = np.random.permutation(y_idx_train)\\n\\nX_train = X_train[y_idx_train,:]\\ny_train = y_train[y_idx_train]\\n\\nsio.savemat('covtype_reduced.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\\n\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load your data (don't touch, just run)\n",
    "\"\"\"\n",
    "data = []\n",
    "f = open('covtype.data','r')\n",
    "while(1):\n",
    "    line = f.readline()\n",
    "    if  len(line) < 100:\n",
    "        print line\n",
    "    \n",
    "    if len(line) == 0: break\n",
    "    data.append(np.array([float(k) for k in line.split(',')]))\n",
    "    if len(data) % 100000 == 0:\n",
    "        print len(data)\n",
    "        \n",
    "f.close\n",
    "data = np.vstack(data)\n",
    "N = data.shape[0]\n",
    "idx = np.random.permutation(N)\n",
    "\n",
    "\n",
    "X_test = data[:N/5,:]\n",
    "X_train = data[N/5:,:]\n",
    "y_test = X_test[:,-1]\n",
    "y_train = X_train[:,-1]\n",
    "X_test = X_test[:,:-1]\n",
    "X_train = X_train[:,:-1]\n",
    "\n",
    "\n",
    "sio.savemat('covtype.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\n",
    "\n",
    "data = sio.loadmat('covtype.mat')\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train'][0]\n",
    "y_test = data['y_test'][0]\n",
    "\n",
    "y_idx_train = [np.where(np.equal(y_train,k))[0] for k in np.unique(y_train)]\n",
    "\n",
    "for i in xrange(len(y_idx_train)):\n",
    "    y_idx = y_idx_train[i]\n",
    "    y_idx_train[i] = y_idx[np.random.choice(len(y_idx),len(y_idx)/1000+1,replace=False)]\n",
    "    \n",
    "y_idx_train = np.hstack(y_idx_train)\n",
    "y_idx_train = np.random.permutation(y_idx_train)\n",
    "\n",
    "X_train = X_train[y_idx_train,:]\n",
    "y_train = y_train[y_idx_train]\n",
    "\n",
    "sio.savemat('covtype_reduced.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7.] [1. 2. 3. 4. 5. 6. 7.]\n(468, 54) (116202, 54) (468,) (116202,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = sio.loadmat('../covertype_release/covtype_reduced.mat')\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train'][0]\n",
    "y_test = data['y_test'][0]\n",
    "\n",
    "print (np.unique(y_train), np.unique(y_test))\n",
    "\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "entropy =  3.314182323161083\nconditional entropy =  3.3029598816135173\n"
     ]
    }
   ],
   "source": [
    "def entropy(label):\n",
    "    entropy = 0\n",
    "    for i in np.unique(label):\n",
    "        count_i = len(label[label == i])\n",
    "        count = len(label)\n",
    "        entropy += -(count_i/count)*np.log2((count_i/count)) if count_i != count else 0\n",
    "    return entropy\n",
    "\n",
    "def cond_entropy(label,split):\n",
    "    cond_entropy = 0\n",
    "    for i in np.unique(label):\n",
    "        for j in np.unique(split):\n",
    "            count_i_j = len(label[(label == i) & (split == j)])\n",
    "            count_j = len(split[split == j])\n",
    "            count = len(split)\n",
    "            cond_entropy += -(count_i_j/count)*np.log2(count_i_j/count_j) if count_i_j != 0 else 0\n",
    "\n",
    "    return cond_entropy\n",
    "\n",
    "random_sequences = sio.loadmat('../covertype_release/random_sequences.mat')\n",
    "\n",
    "s1 = random_sequences['s1'][0]\n",
    "s2 = random_sequences['s2'][0]\n",
    "\n",
    "print ('entropy = ', entropy(s1))\n",
    "print ('conditional entropy = ', cond_entropy(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "information gained in first step 0.00870782472864251\n"
     ]
    }
   ],
   "source": [
    "def find_best_split(x,y):\n",
    "    best_feat = 0\n",
    "    splitval = 0.\n",
    "    set1 = range(len(y)//2)\n",
    "    set2 = range(len(y)//2,len(y))\n",
    "    return best_feat, splitval, set1, set2\n",
    "\n",
    "\n",
    "best_feat, splitval, set1, set2 = find_best_split(X_train, y_train)\n",
    "y_new = y_train * 0\n",
    "y_new[set1] = 1\n",
    "print ('information gained in first step', entropy(y_train) - cond_entropy(y_train,y_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity(y):\n",
    "    return ss.mode(y)[1]/len(y+0.)\n",
    "    \n",
    "class Node:\n",
    "    def __init__(self,  sample_idx, nodeid,  is_leaf = True):\n",
    "        self.is_leaf = is_leaf\n",
    "        self.id = nodeid\n",
    "        self.sample_idx = sample_idx\n",
    "        self.children = []\n",
    "        \n",
    "    def visit_node(self, x):\n",
    "        if self.is_leaf:\n",
    "            return self.label\n",
    "        \"\"\" Fill me in \"\"\"\n",
    "        return self.children[0].visit_node(x)\n",
    "        \n",
    "    def add_split_details(self, splitfeat, splitval)  :\n",
    "        self.splitfeat = splitfeat\n",
    "        self.splitval = splitval\n",
    "    \n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self, x,y):\n",
    "        m = len(y)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.maxid = -1\n",
    "        self.root = self.construct_node(np.array(range(m)))\n",
    "        self.leaves = [self.root]\n",
    "        \n",
    "    def print_tree(self):\n",
    "        print ('printing tree...')\n",
    "        def print_node(parent, node):\n",
    "            print (node.id, )\n",
    "            \n",
    "            if parent is not None:\n",
    "                print (', parent ', parent.id,)\n",
    "            else:\n",
    "                print (', ROOT', )\n",
    "                \n",
    "            print (', label ', node.label, )\n",
    "            if node.is_leaf: \n",
    "                print (', LEAF, ', 'nsamples %d, purity %.2f' %(len(node.sample_idx), purity(self.y[node.sample_idx])))\n",
    "            else:\n",
    "                print (', NONLEAF, split %d, val %.2f' % (node.splitfeat, node.splitval))\n",
    "            if not node.is_leaf:\n",
    "                for ch in node.children:\n",
    "                    print_node(node, ch)\n",
    "        print_node(None, self.root)\n",
    "        \n",
    "        \n",
    "    def construct_node(self, sample_idx):\n",
    "        node = Node(sample_idx, self.maxid + 1,  True)\n",
    "        node.label = 0 # fill me in\n",
    "        node.entropy = entropy(self.y[sample_idx])\n",
    "        node.num_mistakes = np.sum(np.not_equal(node.label, self.y[sample_idx]))\n",
    "        self.maxid += 1\n",
    "        return node\n",
    "        \n",
    "    def report_train_err(self):\n",
    "        total_mistakes = 0\n",
    "        for leaf in self.leaves:\n",
    "            total_mistakes += leaf.num_mistakes\n",
    "        return total_mistakes / (len(self.y)+0.)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        return self.root.visit_node(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "printing tree...\n",
      "0\n",
      ", ROOT\n",
      ", label  0\n",
      ", LEAF,  nsamples 468, purity 0.44\n",
      "current train err: 1.0\n",
      "current test err: 1.0\n",
      "printing tree...\n",
      "0\n",
      ", ROOT\n",
      ", label  0\n",
      ", NONLEAF, split 0, val 0.00\n",
      "1\n",
      ", parent  0\n",
      ", label  0\n",
      ", LEAF,  nsamples 234, purity 0.43\n",
      "2\n",
      ", parent  0\n",
      ", label  0\n",
      ", LEAF,  nsamples 234, purity 0.44\n",
      "one step train err: 1.0\n",
      "one step test err: 1.0\n"
     ]
    }
   ],
   "source": [
    "def get_test_err(tree):\n",
    "    # get test error\n",
    "    num_test_mistakes = 0\n",
    "    for k in range(len(y_test)):\n",
    "        x,y = X_test[k,:],y_test[k]\n",
    "        if y != tree.predict(x):\n",
    "            num_test_mistakes += 1\n",
    "    return num_test_mistakes / (len(y_test)+0.)\n",
    "\n",
    "tree = Tree(X_train,y_train)\n",
    "tree.print_tree()\n",
    "print ('current train err:', tree.report_train_err())\n",
    "print ('current test err:', get_test_err(tree))\n",
    "\n",
    "\n",
    "# my first split\n",
    "best_feat, splitval, set1, set2 = find_best_split(X_train, y_train)\n",
    " \n",
    "left_child = tree.construct_node(set1)\n",
    "right_child = tree.construct_node(set2)\n",
    "tree.root.is_leaf = False\n",
    "tree.leaves.pop(tree.leaves.index(tree.root))\n",
    "tree.root.add_split_details(splitfeat = best_feat, splitval = splitval)\n",
    "\n",
    "\n",
    "tree.root.children = [left_child, right_child]\n",
    "tree.leaves.extend(tree.root.children)\n",
    "tree.print_tree()\n",
    "print ('one step train err:', tree.report_train_err())\n",
    "print ('one step test err:', get_test_err(tree))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.6.10 64-bit ('py3': conda)",
   "display_name": "Python 3.6.10 64-bit ('py3': conda)",
   "metadata": {
    "interpreter": {
     "hash": "04c40bc1924228ecae069f0a0752ec329fab5eb29451cd4e89c215b5a2e0afc3"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}