{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\ncorpus = []\\nf = open(\\'alice_in_wonderland.txt\\',\\'r\\')\\nwhile(1):\\n    line =  f.readline()\\n    if len(line) == 0: break\\n    corpus.extend(line.split())\\n        \\nf.close()\\n\\n\\ndef clean_word(word):\\n    word = word.lower().strip()\\n    for punctuation in [\\'*\\',\\'\"\\',\"\\'\",\\'.\\',\\',\\',\\'-\\',\\'?\\',\\'!\\',\\';\\',\\':\\',\\'\\xe2\\x80\\x94\\',\\'(\\',\\')\\',\\'[\\',\\']\\']:\\n        \\n        word = \\'\\'.join(word.split(punctuation))\\n    \\n    return word\\n\\ncorpus = [clean_word(word) for word in corpus]\\ncorpus = [word for word in corpus if len(word) > 0]\\n\\ncorrupted_corpus = copy.deepcopy(corpus)\\n\\np = .25\\nalphabet = \\'abcdefghijklmnopqrstuvwxyz\\'\\nfor k in xrange(len(corrupted_corpus)):\\n    word = corrupted_corpus[k]\\n    if len(word) < 2: continue\\n    if np.random.rand() < p:\\n        if np.random.randn() < 0:\\n            swap = np.random.choice(range(len(word)), size=2, replace = False)\\n            swap = np.sort(swap)\\n            word = \\'\\'.join([word[:swap[0]], word[swap[1]], word[swap[0]+1:swap[1]], word[swap[0]], word[swap[1]+1:]])\\n        else:\\n            \\n            replace = np.random.choice(range(len(word)), size=1, replace = False)[0]\\n            replace_with = alphabet[np.random.choice(range(len(alphabet)),size=1)[0]]\\n            word = \\'\\'.join([word[:replace], replace_with, word[replace+1:]])\\n        \\n        corrupted_corpus[k] = word\\n\\npickle.dump({\\'corpus\\':corpus,\\'corrupted_corpus\\':corrupted_corpus},open(\\'alice_spelling.pkl\\',\\'wb\\'))\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#This was the process used to load and clean the corpus, and produce the corrupted corpus.\n",
    "#You don't need to do anything here.\n",
    "\"\"\"\n",
    "corpus = []\n",
    "f = open('alice_in_wonderland.txt','r')\n",
    "while(1):\n",
    "    line =  f.readline()\n",
    "    if len(line) == 0: break\n",
    "    corpus.extend(line.split())\n",
    "        \n",
    "f.close()\n",
    "\n",
    "\n",
    "def clean_word(word):\n",
    "    word = word.lower().strip()\n",
    "    for punctuation in ['*','\"',\"'\",'.',',','-','?','!',';',':','â€”','(',')','[',']']:\n",
    "        \n",
    "        word = ''.join(word.split(punctuation))\n",
    "    \n",
    "    return word\n",
    "\n",
    "corpus = [clean_word(word) for word in corpus]\n",
    "corpus = [word for word in corpus if len(word) > 0]\n",
    "\n",
    "corrupted_corpus = copy.deepcopy(corpus)\n",
    "\n",
    "p = .25\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "for k in xrange(len(corrupted_corpus)):\n",
    "    word = corrupted_corpus[k]\n",
    "    if len(word) < 2: continue\n",
    "    if np.random.rand() < p:\n",
    "        if np.random.randn() < 0:\n",
    "            swap = np.random.choice(range(len(word)), size=2, replace = False)\n",
    "            swap = np.sort(swap)\n",
    "            word = ''.join([word[:swap[0]], word[swap[1]], word[swap[0]+1:swap[1]], word[swap[0]], word[swap[1]+1:]])\n",
    "        else:\n",
    "            \n",
    "            replace = np.random.choice(range(len(word)), size=1, replace = False)[0]\n",
    "            replace_with = alphabet[np.random.choice(range(len(alphabet)),size=1)[0]]\n",
    "            word = ''.join([word[:replace], replace_with, word[replace+1:]])\n",
    "        \n",
    "        corrupted_corpus[k] = word\n",
    "\n",
    "pickle.dump({'corpus':corpus,'corrupted_corpus':corrupted_corpus},open('alice_spelling.pkl','wb'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('current recovery rate', 0.7716434266712013)\n('prob not misspelling alice vs alace', 0.80000000000000004)\n('prob not misspelling alice vs earth', 9.9999999999999995e-07)\n('prob not misspelling machinelearning vs machinedreaming', 0.66666666666666663)\n('prob not misspelling machinelearning vs artificalintell', 9.9999999999999995e-07)\n"
     ]
    }
   ],
   "source": [
    "#Take a look at how the data looks, and let's make some helper functions.\n",
    "data = pickle.load(open('alice_spelling.pkl','rb'))\n",
    "vocab = np.unique(data['corpus'])\n",
    "V = len(vocab)\n",
    "\n",
    "\n",
    "## CORRECT VS INCORRECT CORPUS\n",
    "##For now, we will hold onto both the correct and incorrect corpuses. Later, you will only process the incorrect corpus, and the correct corpus is only used as a reference to check for recovery accuracy.\n",
    "def recovery_rate(new_corpus, correct_corpus):\n",
    "    wrong = 0\n",
    "    for k in xrange(len(new_corpus)):\n",
    "        if new_corpus[k] != correct_corpus[k]:\n",
    "            wrong += 1\n",
    "    return 1.- wrong/(len(new_corpus)+0.)\n",
    "print ('current recovery rate', recovery_rate(data['corpus'],data['corrupted_corpus'] ))\n",
    "\n",
    "## Probability of a word mispelling\n",
    "## We will use the following function to predict whether a misspelled word was actually another word. To avoid numerical issues, we make sure that the probablity is always something nonzero.\n",
    "def prob_correct(word1,word2):\n",
    "    SMALLNUM = 0.000001\n",
    "    if len(word1) != len(word2): return SMALLNUM\n",
    "    num_wrong = np.sum(np.array([word1[k] == word2[k] for k in xrange(len(word1))]))\n",
    "    return np.maximum(num_wrong / (len(word1) + 0.),SMALLNUM)\n",
    "\n",
    "print ('prob not misspelling alice vs alace', prob_correct('alice','alace'))\n",
    "print ('prob not misspelling alice vs earth', prob_correct('alice','earth'))\n",
    "print ('prob not misspelling machinelearning vs machinedreaming', prob_correct('machinelearning','machinedreaming'))\n",
    "print ('prob not misspelling machinelearning vs artificalintell', prob_correct('machinelearning','artificalintell'))\n",
    "\n",
    "##HASHING\n",
    "#all of our objects should be vectors of length V or matrices which are V x V. \n",
    "#the kth word in the vocab list is represented by the kth element of the vector, and the relationship between the i,jth words is represented in the i,jth element in the matrix.\n",
    "# to easily go between the word indices and words themselves, we need to make a hash table. \n",
    "vocab_hash = {}\n",
    "for k in xrange(len(vocab)):\n",
    "    vocab_hash[vocab[k]] = k\n",
    "    \n",
    "#now, to access the $k$th word, we do vocab[k]. To access the index of a word, we call vocab_hash[word].\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "prob. of \"alice\" 0.0145486150474\n",
      "prob. of \"queen\" 0.00256962551487\n",
      "prob. of \"chapter\" 0.000906926652307\n",
      "prob. of \"the alice\" 0.0\n",
      "prob. of \"the queen\" 0.0396825396825\n",
      "prob. of \"the chapter\" 0.0\n",
      "prob. of \"the hatter\" 0.0311355311355\n"
     ]
    }
   ],
   "source": [
    "## FILL ME IN ##\n",
    "\n",
    "#WORD FREQUENCY\n",
    "#create an array of length V where V[k] returns the normalized frequency of word k in the entire data corpus. Do so by filling in this function.\n",
    "def get_word_prob(corpus):\n",
    "    word_prob = np.ones(V, dtype=np.float64)/(V+0.)\n",
    "    corpus_hash = list(map(lambda x: vocab_hash[x], corpus))\n",
    "    counts = np.unique(corpus_hash, return_counts=True)\n",
    "    counts = list(zip(counts[0],counts[1]))\n",
    "    for i, j in counts:\n",
    "        word_prob[i] = j/(len(corpus)+0.)\n",
    "    return word_prob\n",
    "\n",
    "word_prob =  get_word_prob(data['corpus'])\n",
    "\n",
    "#report the answer of the following:\n",
    "print 'prob. of \"alice\"', word_prob[vocab_hash['alice']]\n",
    "print 'prob. of \"queen\"', word_prob[vocab_hash['queen']]\n",
    "print 'prob. of \"chapter\"', word_prob[vocab_hash['chapter']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pr(word | prev word) \n",
    "#Using the uncorrupted corpus, accumulate the conditional transition probabilities. Do so via this formula:\n",
    "# pr(word | prev) = max(# times 'prev' preceded 'word' , 1) / # times prev appears\n",
    "# where again, we ensure that this number is never 0 with some small smoothing.\n",
    "def get_transition_matrix(corpus):\n",
    "\n",
    "    temp_transition_matrix = np.zeros((len(vocab),len(vocab)), dtype=np.float64)\n",
    "    transition_matrix = np.zeros((len(vocab),len(vocab)), dtype=np.float64)\n",
    "    corpus_hash = np.array(list(map(lambda x: vocab_hash[x],corpus))).reshape(-1, 1)\n",
    "    #[I, Am, Adithya, Ganesan] -> [1,2,3,4]\n",
    "    prev_word_hash_matrix = np.concatenate([corpus_hash[:-1], corpus_hash[1:]], axis=1)\n",
    "    #[1,2,3,4] -> [[1,2], [2,3], [3,4]]\n",
    "    \n",
    "    for prev, word in prev_word_hash_matrix:\n",
    "        temp_transition_matrix[word, prev] = temp_transition_matrix[word, prev]+1 \n",
    "    #temp_transition_matrix[transition_matrix==0] = 1\n",
    "\n",
    "    for i in range(V):\n",
    "        #transition_matrix[:, i] /= (corpus.count(i))\n",
    "        transition_matrix[:, i] = temp_transition_matrix[:, i]/(word_prob[i]*len(corpus))\n",
    "\n",
    "    return transition_matrix\n",
    "\n",
    "transition_matrix = get_transition_matrix(data['corpus'])\n",
    "print 'prob. of \"the alice\"', transition_matrix[vocab_hash['alice'],vocab_hash['the']]\n",
    "print 'prob. of \"the queen\"', transition_matrix[vocab_hash['queen'],vocab_hash['the']]\n",
    "print 'prob. of \"the chapter\"', transition_matrix[vocab_hash['chapter'],vocab_hash['the']]\n",
    "print 'prob. of \"the hatter\"', transition_matrix[vocab_hash['hatter'],vocab_hash['the']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['abide', 'alice', 'above', 'voice', 'alive', 'twice', 'thick', 'dance', 'stick', 'prize']\n"
     ]
    }
   ],
   "source": [
    "#The prior probabilities are just the word frequencies\n",
    "prior = word_prob  + 0.\n",
    "\n",
    "#write a function that returns the emission probability of a potentially misspelled word, by comparing its probabilities against every word in the correct vocabulary\n",
    "def get_emission(mword):\n",
    "    emission = np.empty((V,))\n",
    "    for word in vocab:\n",
    "        emission[vocab_hash[word]] = prob_correct(word, mword)\n",
    "    return emission\n",
    "\n",
    "#find the 10 closest words to 'abice' and report them\n",
    "idx = np.argsort(get_emission('abice'))[::-1]\n",
    "print [vocab[j] for j in idx[:10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we reduce our attention to a small segment of the corrupted corpus\n",
    "corrupt_corpus =   data['corrupted_corpus'][:1000]\n",
    "correct_corpus =   data['corpus'][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('alices', 'alices'), ('adventures', 'adventures'), ('in', 'in'), ('wonderland', 'wonderland'), ('yb', 'by'), ('lewia', 'lewis'), ('carroll', 'carroll'), ('the', 'the'), ('millennium', 'millennium'), ('fulcrkm', 'fulcrum'), ('edition', 'edition'), ('30', '30'), ('contents', 'contents'), ('chapter', 'chapter'), ('i', 'i'), ('down', 'down'), ('tqe', 'the'), ('raibbthole', 'rabbithole'), ('chapter', 'chapter'), ('ii', 'ii')]\n"
     ]
    }
   ],
   "source": [
    "print (list(zip(corrupt_corpus, correct_corpus))[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_probs = np.ones((len(corrupt_corpus), V))/(V+0.)*0\n",
    "for t, word in enumerate(corrupt_corpus):\n",
    "    if t != 0:\n",
    "        emission = get_emission(word)\n",
    "        for k in range(V):\n",
    "            forward_probs[t, :] += (emission*transition_matrix[:,k]*forward_probs[t-1, k])\n",
    "    else:\n",
    "        forward_probs[t, :] = prior#(get_emission(word)*prior)\n",
    "    forward_probs[t, :] = forward_probs[t, :]/ np.sum(forward_probs[t, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.759 0.797\n"
     ]
    }
   ],
   "source": [
    "proposed_corpus = []\n",
    "for j, word in enumerate(corrupt_corpus):\n",
    "    corrected_word = vocab[np.argsort(forward_probs[j])[-1]]\n",
    "    proposed_corpus.append(corrected_word)\n",
    "print recovery_rate(corrupt_corpus, correct_corpus), recovery_rate(proposed_corpus, correct_corpus)\n",
    "#for k in xrange(100):\n",
    "    #print proposed_corpus[k], corrupt_corpus[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_probs = np.ones((len(corrupt_corpus), V))/(V+0.)*0\n",
    "T = len(corrupt_corpus)\n",
    "for t in reversed(range(T)):\n",
    "    if t == T-1:\n",
    "        #backward_probs[t, :] = (get_emission(corrupt_corpus[t]))\n",
    "        #backward_probs[t, :] =  np.sum(get_emission(corrupt_corpus[t])*transition_matrix, axis=1)\n",
    "        backward_probs[t, :] = np.ones(backward_probs[t, :].shape)\n",
    "    else:\n",
    "        #for k in range(V):\n",
    "            #backward_probs[t, :] += (transition_matrix[k, :]*get_emission(corrupt_corpus[t+1])*backward_probs[t+1, j])\n",
    "        temp = (backward_probs[t+1]*get_emission(corrupt_corpus[t+1])).reshape(1, -1)\n",
    "        backward_probs[t, :] = np.dot(temp, transition_matrix).reshape(-1, )\n",
    "        backward_probs[t, :] = backward_probs[t, :]/ np.sum(backward_probs[t, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.759 0.078\nreduced in\nimportant the\nweeks air\ntreaclewelleh im\nsuet afraid\nadvise but\nyou you\ndreaming might\nthunderstorm zatch\ncheshire a\nzigzag bat\nromeno and\ntricks thats\nshaped very\nvii yike\nenglish a\nwashingextra uomse\nmuchnessyou yot\ncheshire know\nairs but\nhate do\nshell cats\nfifth eat\negg bats\nturkey i\nraving wodner\nforehead and\nfitted here\ntheyve alice\nrising began\nshell to\nfishand get\nlanguid rather\nzigzag sleepy\nhurriedly and\neel went\npaw on\nfancywhos saying\nraised zo\nsnatch herswlf\nthunderstorm in\na a\nhelpless dregmy\nparts sort\ncommon of\nairs way\nhated do\nshell cast\nhate eat\nlikes bats\nhated od\nshell cats\nelses eat\nzigzag bats\ngrowing and\nairs uometimes\nhate do\nshell tabs\nhate eat\ncares cats\ncouple ror\ndripping yuo\ncurtseying see\nwhom as\nthey she\ncouldnt couldnt\nvisit answer\ndifficult either\nuncorked question\nyours it\nsignifies didnt\nma hucm\nwritingdesks matter\ncommon which\nbusy way\nsetting she\nbeor put\nafore it\narchbishop she\nthingseverything felt\nxi that\nfortunately ehs\ngreat was\nhas dozing\nzigzag fof\njaw and\nworried had\ntheyve just\nhm begun\nwonderful to\nriddles dream\ncrashnow that\nrudeness ehs\nwants was\nelses walking\nfix hnad\nforwards in\nchains hadn\nteatime with\nzigzag dinah\n"
     ]
    }
   ],
   "source": [
    "proposed_corpus = []\n",
    "for j, word in enumerate(corrupt_corpus):\n",
    "    corrected_word = vocab[np.argsort(backward_probs[j])[-1]]\n",
    "    proposed_corpus.append(corrected_word)\n",
    "print recovery_rate(corrupt_corpus, correct_corpus), recovery_rate(proposed_corpus, correct_corpus)\n",
    "for k in xrange(-100, 0):\n",
    "    print proposed_corpus[k], corrupt_corpus[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.759 0.906\n",
      "a alices\n",
      "adventures adventures\n",
      "in in\n",
      "wonderland wonderland\n",
      "by yb\n",
      "lewis lewia\n",
      "carroll carroll\n",
      "the the\n",
      "millennium millennium\n",
      "fulcrum fulcrkm\n",
      "edition edition\n",
      "30 30\n",
      "contents contents\n",
      "chapter chapter\n",
      "i i\n",
      "dont down\n",
      "the tqe\n",
      "rabbithole raibbthole\n",
      "chapter chapter\n",
      "ii ii\n",
      "the the\n",
      "pool pooo\n",
      "of of\n",
      "tears aetrs\n",
      "chapter chapter\n",
      "iii dii\n",
      "a a\n",
      "caucusrace caucusrace\n",
      "and and\n",
      "a a\n",
      "long long\n",
      "tale tael\n",
      "chapter yhapter\n",
      "iv iv\n",
      "the the\n",
      "rabbit raibbt\n",
      "sends sends\n",
      "in ni\n",
      "a a\n",
      "little littme\n",
      "bill bill\n",
      "chapter chapter\n",
      "v v\n",
      "advice advice\n",
      "from from\n",
      "a a\n",
      "caterpillar raterpillac\n",
      "chapter chapter\n",
      "vi vi\n",
      "pig piz\n",
      "and xnd\n",
      "pepper pepper\n",
      "chapter chapter\n",
      "vii vii\n",
      "a a\n",
      "mad amd\n",
      "teaparty teaparty\n",
      "chapter chapter\n",
      "viii viii\n",
      "the the\n",
      "queens zueens\n",
      "croquetground croquetground\n",
      "chapter chapter\n",
      "iv ic\n",
      "the the\n",
      "mock mock\n",
      "turtles turtles\n",
      "story story\n",
      "chapter chapter\n",
      "x x\n",
      "the the\n",
      "lobster lsboter\n",
      "quadrille quadrille\n",
      "chapter chartep\n",
      "xi xi\n",
      "who who\n",
      "stole stole\n",
      "the eht\n",
      "tarts tarts\n",
      "chapter chapter\n",
      "xii xii\n",
      "alices alices\n",
      "evidence nvideece\n",
      "chapter chapter\n",
      "i i\n",
      "dont donw\n",
      "the the\n",
      "rabbithole raebithole\n",
      "alice alice\n",
      "was was\n",
      "beginning beginning\n",
      "to to\n",
      "get get\n",
      "very very\n",
      "tired tired\n",
      "of of\n",
      "sitting sitting\n",
      "by by\n",
      "her her\n",
      "sister sister\n"
     ]
    }
   ],
   "source": [
    "probs = forward_probs*backward_probs\n",
    "proposed_corpus = []\n",
    "for j, word in enumerate(corrupt_corpus):\n",
    "    corrected_word = vocab[np.argsort(probs[j])[-1]]\n",
    "    proposed_corpus.append(corrected_word)\n",
    "print recovery_rate(corrupt_corpus, correct_corpus), recovery_rate(proposed_corpus, correct_corpus)\n",
    "for k in xrange(100):\n",
    "    print proposed_corpus[k], corrupt_corpus[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = np.concatenate([np.array(proposed_corpus).reshape(-1,1), np.array(corrupt_corpus).reshape(-1,1), np.array(correct_corpus).reshape(-1,1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(36, 3)\n"
     ]
    }
   ],
   "source": [
    "a = corpora[(corpora[:, 1] != corpora[:, 2])&(corpora[:, 2] != corpora[:, 0])]\n",
    "print (a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\\begin{tabular}{lll}\n\\toprule\nProposed &  Corrupt &  Correct \\\\\n\\midrule\n      iv &       ic &       ix \\\\\n    dont &     donw &     down \\\\\n      to &       fo &       of \\\\\n      to &       ro &       or \\\\\n   alice &    twcce &    twice \\\\\n      or &       on &       no \\\\\n      to &       fo &       of \\\\\n getting &  nlthing &  nothing \\\\\n     was &      bus &      but \\\\\n      to &       ta &       at \\\\\n      to &       ti &       it \\\\\n      to &       ti &       it \\\\\n herself &  flasred &  flashed \\\\\n  before &   caross &   across \\\\\n    make &     taze &     take \\\\\n      as &       af &       of \\\\\n      to &       ti &       it \\\\\n    with &     lika &     like \\\\\n    that &     thne &     then \\\\\n      to &       ta &       at \\\\\n      so &       sa &       as \\\\\n    with &     nito &     into \\\\\n      to &       fo &       of \\\\\n      or &       ot &       to \\\\\n      so &       fo &       of \\\\\n      to &       ta &       at \\\\\n   after &    nrvee &    never \\\\\n    some &     comj &     come \\\\\n      of &       ot &       to \\\\\n      to &       fo &       of \\\\\n      of &       ot &       to \\\\\n      to &       fo &       of \\\\\n    with &     wtah &     what \\\\\n      in &       on &       no \\\\\n      or &       od &       do \\\\\n    cats &     tabs &     bats \\\\\n\\bottomrule\n\\end{tabular}\n\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(a, columns=[\"Proposed\", \"Corrupt\", \"Correct\"]).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(205, 3)\n"
     ]
    }
   ],
   "source": [
    "b = corpora[(corpora[:, 1] != corpora[:, 2])&(corpora[:, 2] == corpora[:, 0])]\n",
    "print b.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\\begin{tabular}{lll}\n\\toprule\n    Proposed &      Corrupt &      Correct \\\\\n\\midrule\n        this &         bhis &         this \\\\\n          on &           cn &           on \\\\\n          so &           ss &           so \\\\\n       heads &        hdaes &        heads \\\\\n        this &         bhis &         this \\\\\n        very &         vhry &         very \\\\\n        once &         onec &         once \\\\\n       didnt &        dindt &        didnt \\\\\n      wonder &       wodner &       wonder \\\\\n         the &          thd &          the \\\\\n          no &           qo &           no \\\\\n          it &           iv &           it \\\\\n         hot &          hto &          hot \\\\\n         the &          tge &          the \\\\\n         say &          soy &          say \\\\\n         had &          hat &          had \\\\\n         ask &          aik &          ask \\\\\n      queens &       zueens &       queens \\\\\n     dinahll &      diwahll &      dinahll \\\\\n          up &           cp &           up \\\\\n       mouse &        uomse &        mouse \\\\\n          to &           fo &           to \\\\\n       brave &        rbave &        brave \\\\\n         she &          ehs &          she \\\\\n       never &        neder &        never \\\\\n         the &          tee &          the \\\\\n        fall &         fahl &         fall \\\\\n        took &         tkok &         took \\\\\n caterpillar &  raterpillac &  caterpillar \\\\\n       didnt &        dindt &        didnt \\\\\n      either &       aither &       either \\\\\n     chapter &      chartep &      chapter \\\\\n      dreamy &       dregmy &       dreamy \\\\\n         was &          wsa &          was \\\\\n          or &           gr &           or \\\\\n         get &          gte &          get \\\\\n\\bottomrule\n\\end{tabular}\n\n"
     ]
    }
   ],
   "source": [
    "r = np.random.randint(0, b.shape[0], size=(36,))\n",
    "print(pd.DataFrame(b[r], columns=[\"Proposed\", \"Corrupt\", \"Correct\"]).to_latex(index=False))"
   ]
  },
  {
   "source": [
    "# encode the HMM spelling corrector. To debug, you can see the first hundred words of both the corrupted and proposed corpus, to see if spelling words got corrupted.\n",
    "\n",
    "# report the recovery rate of the proposed (corrected) corpus.\n",
    "\n",
    "#forward step\n",
    "forward_probs = np.ones((len(corrupt_corpus), V))/(V+0.)*0\n",
    "for t, word in enumerate(corrupt_corpus):\n",
    "    if t != 0:\n",
    "        emission = get_emission(word)\n",
    "        for k in range(V):\n",
    "            forward_probs[t, :] += (emission*transition_matrix[:,k]*forward_probs[t-1, k])\n",
    "        forward_probs[t, :] = forward_probs[t, :]/ np.sum(forward_probs[t, :])\n",
    "    else:\n",
    "        forward_probs[t, :] = (get_emission(word)*prior)\n",
    "        forward_probs[t, :] = forward_probs[t, :]/ np.sum(forward_probs[t, :])\n",
    "    \n",
    "# backward step\n",
    "backward_probs = np.ones((len(corrupt_corpus), V))/(V+0.)*0\n",
    "\n",
    "\n",
    "# compute corrected corpus\n",
    "proposed_corpus = copy.deepcopy(corrupt_corpus)\n",
    "for k in xrange(100):\n",
    "    print proposed_corpus[k], corrupt_corpus[k]\n",
    "\n",
    "print recovery_rate(corrupt_corpus, correct_corpus), recovery_rate(proposed_corpus, correct_corpus) \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 2.7.12 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}